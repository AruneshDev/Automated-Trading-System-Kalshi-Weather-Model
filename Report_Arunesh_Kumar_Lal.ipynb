{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-542 Principles of Machine Learning Common Task Report\n",
    "### Submitted by: Arunesh Kumar Lal (U26502933)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "\n",
    "The common task assigned to us was using ML model to predict daily climate events in four major cities.\n",
    "The task was divided into three week (three stages)\n",
    "\n",
    "- Week 1:\n",
    "\n",
    "Manually trade on demo Kalshi Platform using online data sources predicting the max temperature of \n",
    "NYC, Miami,Austin and Chicago.\n",
    "\n",
    "- Week 2: Data collection and model training\n",
    "\n",
    "Identified 5 different data sources that can be used for predicting your daily climate event.\n",
    "Used the data from these sources to train a machine learning model to predict the daily climate event. \n",
    "Plot the predicted and ground truth values over time for historic data. \n",
    "Make daily manual trades based on your model's predictions.\n",
    "\n",
    "- Week 3: Automated Prediction\n",
    "\n",
    "Now using the documentation provided and started code. Automated my trades for Kalshi account based on my prediction output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Overview of my work\n",
    "### Data Sources for Manual Prediction\n",
    "- The Weather Channel\n",
    "- Accu Weather \n",
    "- The Washington Post news on Weather prediction apps\n",
    "\n",
    "\n",
    "### Event:\n",
    "Once I set up my account with $10.5K in the demo Kalshi Account. I started placing trades on The highest temperature for each city. \n",
    "I have only considered Settled trades for my final report. \n",
    "Event Tickers: \n",
    "- nycTicker = 'HIGHNY'\n",
    "- ausTicker = 'HIGHAUS'\n",
    "- chiTicker = 'HIGHCHI'\n",
    "- miaTicker = 'HIGHMIA'\n",
    "I placed a trade based on weekly assigned task for max temp. of each city for that particular day. If by the end-of-day the maximum temperature of the city is in some range, say x to y, then the market resolves to 'yes' for that value, i.e., \"x to y\" market will resolve to yes. And normally y-x = 1. Hence accuracy and precision play an important role in selecting the correct event. \n",
    "\n",
    "### Dataset:\n",
    "I collected my dataset majorly from the website of \"*Visual Crossing*\". I extracted 3 years data for each city in csv.\n",
    "Five Data Sources identified:\n",
    "- National Centers for Environmental Information (NCEI) - (https://www.ncei.noaa.gov/cdo-web/datasets)\n",
    "- The European Centre for Medium-Range Weather Forecasts (ECMWF) - \n",
    "  (https://www.ecmwf.int/en/forecasts/dataset/ecmwf-reanalysis-v5)\n",
    "- National Weather Service (NWS) - Visual Cross Reference \n",
    "- Open-Meteo (https://open-meteo.com/)\n",
    "- The Japanese Meteorological Agency (https://www.data.jma.go.jp/obd/stats/data/en/index.html)\n",
    "- National Oceanic and Atmospheric Administration (NOAA)\n",
    "\n",
    "\n",
    "The dataset has the previous three year's historical data for NYC,Chicago,Miami, and Austin's temperature.\n",
    "The features/labels (column names) of the dataset are as follows:\n",
    "1. tmin : The minimum temperature of that day.\n",
    "2. tmax : The maximum temperature of that day.\n",
    "3. cloudcover: the fraction of the sky obscured by clouds on average when observed from a particular location.\n",
    "4. windgust:Is a sudden, brief increase in speed of the wind\n",
    "5. humidity:a measure of water vapor in the air\n",
    "etc. there were around 28 features in the data \n",
    "\n",
    "There were many such features to consider, I selected these 5 based on their relevance in weather prediction.\n",
    "Let's analyze other features:\n",
    "Our model will predict the next day's maximum temperature of all the 4 cities, i.e., the \"*tempmax*\" feature for the next day will be the output of the model.\n",
    "Input will be the previous years data points, i.e., all the features (including tmax) from the previous few years.\n",
    "Based upon this historical data, our model will try to predict the next day's \"tmax\" output feature.\n",
    "\n",
    "### Model:\n",
    "I have made use of the XGBoost(eXtreme Gradient Boosting)  algorithm which implements gradient boosting trees with additional improvements for better speed and performance. Making it ideal for time-series forcasting.\n",
    "Forecasting in data science and machine learning is a technique used to predict future numerical values based on historical data collected over time, either in regular or irregular intervals.\n",
    "\n",
    "#### Optimizer Used:\n",
    "1. Introduction to Model Optimization\n",
    "The purpose of optimization was to reduce the MSE, and fine tune the model while avoiding overfitting.\n",
    "For temp max prediction fine tuning the model was a requirement as the dataset and features selected were limited and as mentioned in reports weather predictions are 85% accurate on a given day. \n",
    "2. Hyperparameter Selection\n",
    "    The hyperparameter adjusted in the model and its role in the learning process:\n",
    "    n_estimators: The number of trees in the ensemble. Increasing this number can improve model accuracy up to a point, beyond which the model might overfit.\n",
    "\n",
    "    max_depth: The maximum depth of a tree. Controls the complexity of the model. Deeper trees can capture more complex patterns but may lead to overfitting.\n",
    "\n",
    "    learning_rate: Also known as the \"eta\" value, it determines the step size at each iteration while moving toward a minimum of a loss function. A smaller learning rate requires more boosting rounds but can lead to a better generalized model.\n",
    "\n",
    "    colsample_bytree: The fraction of features (columns) used per tree. A lower value provides more regularization.\n",
    "\n",
    "    subsample: The fraction of instances (rows) used for each tree. Lower values prevent overfitting but too low can lead to underfitting.\n",
    "\n",
    "    reg_alpha and reg_lambda: These are L1 (Lasso regression) and L2 (Ridge regression) regularization terms on weights, respectively. They add a penalty on large coefficients to prevent overfitting.\n",
    "\n",
    "    random_state: Ensures reproducibility of results by setting a seed for the random number generator used in XGBoost.\n",
    "\n",
    "    early_stopping_rounds: Stops training if the validation metric does not improve for a specified number of boosting rounds. Helps in preventing overfitting.\n",
    "\n",
    "3. Optimization Methodology \n",
    "   It was mostly trial and error by checking MSE and gridsearch used for automated hyperparameter tuning.\n",
    "\n",
    "4. Impact on Model Performance:\n",
    "There were fluctuations in model's performance going off by 10F or being close to 1F, used MSE to quantify the improvements.\n",
    "\n",
    "5. Conclusion\n",
    "The project was a great learning experience. I think there is more scope in weather forecasting in my model, based on discussion with peers, the dataset size and feature set can be increased to further enhance the model. Automating the trades was a good learning experience.\n",
    "#### Loss Function Used:\n",
    "Mean Squared Error \n",
    "Please refer file : MSE of Settled Trades.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Code:\n",
    "Please refer the file : Final_Prediction_Model.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Automated Trading \n",
    "Please refer the file: KalshiTradingV2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference:\n",
    "- https://www.kdnuggets.com/2023/08/leveraging-xgboost-timeseries-forecasting.html\n",
    "- https://www.visualcrossing.com/weather-data\n",
    "- https://towardsdatascience.com/five-free-and-reliable-weather-data-sources-20b9ea6afac9\n",
    "- https://www.washingtonpost.com/technology/2023/02/23/best-weather-apps/\n",
    "- https://neptune.ai/blog/xgboost-everything-you-need-to-know"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
